{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5adf6e86-dd91-4f02-890b-7ce1a830460e",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 1. Loading and Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2c9c6f7-8817-4f97-8bff-cc6f99f0219e",
   "metadata": {},
   "source": [
    "## 1.1 Import libraries and python files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74b9eb89-c20a-48e6-9e20-941c6f582218",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#import useful libraries \n",
    "import json\n",
    "import sys\n",
    "import requests\n",
    "import calendar\n",
    "import scipy\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm \n",
    "import statsmodels.formula.api as smf\n",
    "import seaborn as sbn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from matplotlib.colors import LogNorm, Normalize\n",
    "from sklearn.preprocessing import normalize\n",
    "from datetime import datetime\n",
    "%matplotlib inline \n",
    "\n",
    "# Import functions helper and loading functions\n",
    "from data_loader import *\n",
    "from helper_functions import *\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "##link to the datasets\n",
    "## https://www.cs.cmu.edu/~ark/personas/\n",
    "##https://www.kaggle.com/datasets/rounakbanik/the-movies-dataset?resource=download&select=movies_metadata.csv\n",
    "##https://www.kaggle.com/datasets/ashirwadsangwan/imdb-dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f542fa64-b706-4caa-ab84-613bb9229da4",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## 1.2 Load the different datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a7b84a4a-1ab6-451c-b7c9-e7bb3b96e077",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "##load datasets from CMU dataset\n",
    "df_character = load_character().copy()\n",
    "df_movie = load_movie().copy()\n",
    "df_name_cluster = load_name_cluster().copy()\n",
    "df_summary = load_plot_summary().copy()\n",
    "df_tropes_cluster = load_tropes_cluster().copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b736a777",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Replace 'id-translation.wikidata.json' with the path to your JSON file\n",
    "file_path = 'id-translation.wikidata.json'\n",
    "\n",
    "# Load the JSON file into a DataFrame\n",
    "df_id_translation = pd.read_json(file_path, orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "958e44bb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Small cleanup\n",
    "df_id_translation = df_id_translation.dropna(subset=['Freebase ID'])\n",
    "df_id_translation.drop_duplicates(subset=['Freebase ID'], keep='first', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "67b2a9d1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# df_movie will be the reference dataframe. After being completed with additional datasets, it must never be modified\n",
    "df_movie = pd.merge(df_movie, df_id_translation, on='Freebase ID', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8180483b-7664-459f-84dd-5d080744699d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The percentage of missing values in Year is 8.444%.\n",
      "The percentage of missing values in Month is 51.832%.\n",
      "The percentage of missing values in Box office is 89.722%.\n",
      "The percentage of missing values in Runtime is 25.018%.\n",
      "The percentage of missing values in tconst is 9.769%.\n"
     ]
    }
   ],
   "source": [
    "#compute percentage of missing values for df_movie\n",
    "values = ['Year', 'Month', 'Box office', 'Runtime', 'tconst']\n",
    "\n",
    "def compute_missing_values(df, values):\n",
    "    for variable in values :\n",
    "        percentage_missing_values = (df[variable].isna().sum()/len(df[variable]))*100\n",
    "        print(f\"The percentage of missing values in {variable} is {format(percentage_missing_values, '.3f')}%.\")\n",
    "\n",
    "    \n",
    "compute_missing_values(df_movie, values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d470997-3782-42f6-ad5c-9c061d37a74b",
   "metadata": {
    "tags": []
   },
   "source": [
    "As we can see, a lot of 'Box office' data is missing. We should add some other database to try to reduce the missing data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b92c14c-f7a3-4b37-8955-48740aa1d7a3",
   "metadata": {},
   "source": [
    "## 1.3 Load addtionnal datasets and merge what we need "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "23805801",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#load imdb dataset (from kaggle)\n",
    "df_imdb_movie = load_movie_imdb_kaggle()\n",
    "df_imdb_rating = load_rating_imdb_kaggle() \n",
    "\n",
    "#merge movies with rating \n",
    "df_movie_rating = pd.merge(df_imdb_movie, df_imdb_rating, on='tconst', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "153d0412",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#merge CMU dataset with IMDB dataset\n",
    "df_movie = pd.merge(df_movie, df_movie_rating[['tconst', 'averageRating', 'numVotes']], on=['tconst'], how='left')\n",
    "#display(df_movie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0fbe01e3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The percentage of missing values in averageRating is 31.271%.\n",
      "The percentage of missing values in numVotes is 31.271%.\n",
      "The number of movies with missing values for 'averageRating' and 'numVotes' is 25561.\n"
     ]
    }
   ],
   "source": [
    "# missing Rating values\n",
    "values = ['averageRating', 'numVotes']\n",
    "\n",
    "compute_missing_values(df_movie, values)\n",
    "print(f\"The number of movies with missing values for 'averageRating' and 'numVotes' is {df_movie['averageRating'].isna().sum()}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1fbba358",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## load kaggle movie metadata\n",
    "df_kaggle_movie = load_movie_kaggle()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5ddefe3a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#merge the datasets on the 'Name' column\n",
    "#df_movie = df_movie.merge(df_kaggle_movie[['Name', 'Year', 'Month', 'Day']], on=['Name', 'Year'], how='left', suffixes=('', '_df2'))\n",
    "df_movie = df_movie.merge(df_kaggle_movie[['Name', 'Year', 'tconst', 'Month', 'Day']], on=['Name', 'Year','tconst'], how='left', suffixes=('', '_df2'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5995d12b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#use 'combine_first' to fill in the 'Box office' values from df_kaggle_movie where they are NaN in df_movie\n",
    "df_movie['Month'] = df_movie['Month'].combine_first(df_movie['Month_df2'])\n",
    "df_movie['Day'] = df_movie['Day'].combine_first(df_movie['Day_df2'])\n",
    "\n",
    "#drop the extra 'Box office' column from df_kaggle_movie\n",
    "df_movie.drop('Month_df2', axis=1, inplace=True)\n",
    "df_movie.drop('Day_df2', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9ae92096",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The percentage of missing values in Year is 8.442%.\n",
      "The percentage of missing values in Month is 42.891%.\n",
      "The percentage of missing values in Box office is 89.721%.\n",
      "The percentage of missing values in Runtime is 25.014%.\n",
      "The percentage of missing values in tconst is 9.767%.\n"
     ]
    }
   ],
   "source": [
    "values = ['Year', 'Month', 'Box office', 'Runtime', 'tconst']\n",
    "compute_missing_values(df_movie, values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "103d62c2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#load oscar reward dataset\n",
    "df_oscar = load_oscar_winner()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2da51686",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#filter the dataframe to only include rows where 'winner' is True\n",
    "df_winner_movie = df_oscar[df_oscar['winner'] == True]\n",
    "\n",
    "#group by the movie name and count the winners time\n",
    "df_winner_movie = df_winner_movie.groupby('Name').agg(\n",
    "    num_oscars_won=pd.NamedAgg(column='winner', aggfunc='size'),\n",
    "    years_won=pd.NamedAgg(column='year_ceremony', aggfunc=lambda x: list(x))\n",
    ").reset_index()\n",
    "\n",
    "#sort the movies by oscars won\n",
    "df_oscar_wins = df_winner_movie.sort_values(by='num_oscars_won', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "43d1d1a9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#merge CUM and oscars awards dataset\n",
    "df_movie = pd.merge(df_movie, df_oscar_wins, left_on='Name', right_on='Name', how='left')\n",
    "\n",
    "#replace NaN values in 'num_oscars_won' with 0 for movies that didn't win any oscars\n",
    "df_movie['num_oscars_won'].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ead13e05",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The percentage of movies having won an oscar is 1.896%.\n"
     ]
    }
   ],
   "source": [
    "percentage_oascar_movies = ((df_movie['num_oscars_won']!=0).sum()/len(df_movie['num_oscars_won']))*100\n",
    "print(f\"The percentage of movies having won an oscar is {format(percentage_oascar_movies, '.3f')}%.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "454466d2-0de1-45e3-a007-f9219a8c9508",
   "metadata": {},
   "source": [
    "## 1.4 Cleanup of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9551a8e3-82cc-41b8-b2c1-76fd147f7167",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Drop the row with 'Year' smaller than 1800 as we have seen somme erronous movie before and there is too few movies after 2014.\n",
    "df_movie = df_movie[(df_movie['Year'] >= 1800) & (df_movie['Year'] <= 2013)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ed2a5df-8922-4d9c-81a3-c0879cfcce4c",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 2. First day of the month"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "611001d6-0256-4e6b-93cd-40287b440450",
   "metadata": {},
   "source": [
    "Let's try to prove that releasing on the 1st day of the month is a mistake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a40a8f61",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_time_stamps = get_time_stamps_df(df_movie)\n",
    "\n",
    "df_time_stamps.rename(columns={'Countries (Freebase ID:name tuples)' : 'Countries',\n",
    "                                'Box office' : 'Box_office',\n",
    "                              'genres (Freebase ID:name tuples)' : 'Genres',\n",
    "                               'Languages (Freebase ID:name tuples)' : 'Languages'\n",
    "                              }, errors=\"raise\", inplace=True)\n",
    "\n",
    "\n",
    "df_time_stamps['Genres']= df_time_stamps['Genres'].apply(lambda x : list(json.loads(x).values()))\n",
    "df_time_stamps['Countries']= df_time_stamps['Countries'].apply(lambda x : list(json.loads(x).values()))\n",
    "df_time_stamps['Languages']= df_time_stamps['Languages'].apply(lambda x : list(json.loads(x).values()))\n",
    "\n",
    "\n",
    "\n",
    "df_time_stamps['is_first_day'] = (df_time_stamps['Day'] == 1).astype(int)\n",
    "\n",
    "df_time_stamps.drop(labels=['Freebase ID', 'Release date', 'tconst'], axis=1, inplace=True)\n",
    "#display(df_time_stamps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e1d67833",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_genre_list = df_time_stamps.copy(deep=True)\n",
    "genres = get_values_column_of_list(df_genre_list, 'Genres')\n",
    "sorted_genres = sorted(genres.items(), key=lambda x:x[1], reverse=True)\n",
    "top_genres = [genre[0] for genre in sorted_genres[:5]]\n",
    "\n",
    "df_country_list = df_time_stamps.copy(deep=True)\n",
    "countries = get_values_column_of_list(df_country_list, 'Countries')\n",
    "sorted_countries = sorted(countries.items(), key=lambda x:x[1], reverse=True)\n",
    "top_countries = [country[0] for country in sorted_countries[:5]]\n",
    "\n",
    "df_language_list = df_time_stamps.copy(deep=True)\n",
    "languages = get_values_column_of_list(df_language_list, 'Languages')\n",
    "sorted_languages = sorted(languages.items(), key=lambda x:x[1], reverse=True)\n",
    "top_languages = [language[0] for language in sorted_languages[:3]]\n",
    "\n",
    "\n",
    "def add_dummies(df, var, top_dummies):\n",
    "    df_dummies = df.copy(deep=True)\n",
    "\n",
    "    for value in top_dummies:\n",
    "        df_dummies[str(value).replace(' ', '_').replace('-','_') + '_onehot'] = df_dummies[var].apply(lambda x: 1 if value in x else 0)\n",
    "    df_dummies.drop(labels=var, axis=1, inplace=True)\n",
    "    return df_dummies\n",
    "\n",
    "df_time_stamps = add_dummies(df_time_stamps, 'Genres', top_genres)\n",
    "df_time_stamps = add_dummies(df_time_stamps, 'Countries', top_countries)\n",
    "df_time_stamps = add_dummies(df_time_stamps, 'Languages', top_languages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "384ec293",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Wikipedia ID</th>\n",
       "      <th>Name</th>\n",
       "      <th>Box_office</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>averageRating</th>\n",
       "      <th>numVotes</th>\n",
       "      <th>num_oscars_won</th>\n",
       "      <th>...</th>\n",
       "      <th>Black_and_white_onehot</th>\n",
       "      <th>Thriller_onehot</th>\n",
       "      <th>United_States_of_America_onehot</th>\n",
       "      <th>United_Kingdom_onehot</th>\n",
       "      <th>India_onehot</th>\n",
       "      <th>France_onehot</th>\n",
       "      <th>Japan_onehot</th>\n",
       "      <th>English_Language_onehot</th>\n",
       "      <th>French_Language_onehot</th>\n",
       "      <th>Silent_film_onehot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>975900</td>\n",
       "      <td>Ghosts of Mars</td>\n",
       "      <td>14010832.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>2001</td>\n",
       "      <td>8</td>\n",
       "      <td>24</td>\n",
       "      <td>4.9</td>\n",
       "      <td>56854.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3196793</td>\n",
       "      <td>Getting Away with Murder: The JonBenét Ramsey ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>95.0</td>\n",
       "      <td>2000</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>13696889</td>\n",
       "      <td>The Gangsters</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1913</td>\n",
       "      <td>5</td>\n",
       "      <td>29</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10408933</td>\n",
       "      <td>Alexander's Ragtime Band</td>\n",
       "      <td>3600000.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>1938</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>6.8</td>\n",
       "      <td>2265.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>6631279</td>\n",
       "      <td>Little city</td>\n",
       "      <td>NaN</td>\n",
       "      <td>93.0</td>\n",
       "      <td>1997</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5.8</td>\n",
       "      <td>1129.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81751</th>\n",
       "      <td>32468537</td>\n",
       "      <td>Shadow Boxing 2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>132.0</td>\n",
       "      <td>2007</td>\n",
       "      <td>10</td>\n",
       "      <td>18</td>\n",
       "      <td>5.8</td>\n",
       "      <td>1066.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81752</th>\n",
       "      <td>35228177</td>\n",
       "      <td>Mermaids: The Body Found</td>\n",
       "      <td>NaN</td>\n",
       "      <td>120.0</td>\n",
       "      <td>2011</td>\n",
       "      <td>3</td>\n",
       "      <td>19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81753</th>\n",
       "      <td>34980460</td>\n",
       "      <td>Knuckle</td>\n",
       "      <td>NaN</td>\n",
       "      <td>96.0</td>\n",
       "      <td>2011</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>6.8</td>\n",
       "      <td>3191.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81754</th>\n",
       "      <td>9971909</td>\n",
       "      <td>Another Nice Mess</td>\n",
       "      <td>NaN</td>\n",
       "      <td>66.0</td>\n",
       "      <td>1972</td>\n",
       "      <td>9</td>\n",
       "      <td>22</td>\n",
       "      <td>5.8</td>\n",
       "      <td>110.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81755</th>\n",
       "      <td>913762</td>\n",
       "      <td>The Super Dimension Fortress Macross II: Lover...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>150.0</td>\n",
       "      <td>1992</td>\n",
       "      <td>5</td>\n",
       "      <td>21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>46680 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Wikipedia ID                                               Name  \\\n",
       "0            975900                                     Ghosts of Mars   \n",
       "1           3196793  Getting Away with Murder: The JonBenét Ramsey ...   \n",
       "5          13696889                                      The Gangsters   \n",
       "7          10408933                           Alexander's Ragtime Band   \n",
       "12          6631279                                        Little city   \n",
       "...             ...                                                ...   \n",
       "81751      32468537                                    Shadow Boxing 2   \n",
       "81752      35228177                           Mermaids: The Body Found   \n",
       "81753      34980460                                            Knuckle   \n",
       "81754       9971909                                  Another Nice Mess   \n",
       "81755        913762  The Super Dimension Fortress Macross II: Lover...   \n",
       "\n",
       "       Box_office  Runtime  Year  Month  Day  averageRating  numVotes  \\\n",
       "0      14010832.0     98.0  2001      8   24            4.9   56854.0   \n",
       "1             NaN     95.0  2000      2   16            NaN       NaN   \n",
       "5             NaN     35.0  1913      5   29            NaN       NaN   \n",
       "7       3600000.0    106.0  1938      8   16            6.8    2265.0   \n",
       "12            NaN     93.0  1997      4    4            5.8    1129.0   \n",
       "...           ...      ...   ...    ...  ...            ...       ...   \n",
       "81751         NaN    132.0  2007     10   18            5.8    1066.0   \n",
       "81752         NaN    120.0  2011      3   19            NaN       NaN   \n",
       "81753         NaN     96.0  2011      1   21            6.8    3191.0   \n",
       "81754         NaN     66.0  1972      9   22            5.8     110.0   \n",
       "81755         NaN    150.0  1992      5   21            NaN       NaN   \n",
       "\n",
       "       num_oscars_won  ... Black_and_white_onehot  Thriller_onehot  \\\n",
       "0                 0.0  ...                      0                1   \n",
       "1                 0.0  ...                      0                0   \n",
       "5                 0.0  ...                      1                0   \n",
       "7                 1.0  ...                      1                0   \n",
       "12                0.0  ...                      0                0   \n",
       "...               ...  ...                    ...              ...   \n",
       "81751             0.0  ...                      0                0   \n",
       "81752             0.0  ...                      0                0   \n",
       "81753             0.0  ...                      0                0   \n",
       "81754             0.0  ...                      0                0   \n",
       "81755             0.0  ...                      0                0   \n",
       "\n",
       "      United_States_of_America_onehot  United_Kingdom_onehot  India_onehot  \\\n",
       "0                                   1                      0             0   \n",
       "1                                   1                      0             0   \n",
       "5                                   1                      0             0   \n",
       "7                                   1                      0             0   \n",
       "12                                  1                      0             0   \n",
       "...                               ...                    ...           ...   \n",
       "81751                               0                      0             0   \n",
       "81752                               1                      0             0   \n",
       "81753                               0                      1             0   \n",
       "81754                               1                      0             0   \n",
       "81755                               0                      0             0   \n",
       "\n",
       "       France_onehot  Japan_onehot  English_Language_onehot  \\\n",
       "0                  0             0                        1   \n",
       "1                  0             0                        1   \n",
       "5                  0             0                        1   \n",
       "7                  0             0                        1   \n",
       "12                 0             0                        1   \n",
       "...              ...           ...                      ...   \n",
       "81751              0             0                        1   \n",
       "81752              0             0                        1   \n",
       "81753              0             0                        1   \n",
       "81754              0             0                        1   \n",
       "81755              0             1                        0   \n",
       "\n",
       "       French_Language_onehot  Silent_film_onehot  \n",
       "0                           0                   0  \n",
       "1                           0                   0  \n",
       "5                           0                   1  \n",
       "7                           0                   0  \n",
       "12                          0                   0  \n",
       "...                       ...                 ...  \n",
       "81751                       0                   0  \n",
       "81752                       0                   0  \n",
       "81753                       0                   0  \n",
       "81754                       0                   0  \n",
       "81755                       0                   0  \n",
       "\n",
       "[46680 rows x 27 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df_time_stamps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32442571",
   "metadata": {},
   "source": [
    "We will use propensity score for the variables : \n",
    "- Genres (somehow)\n",
    "- Year\n",
    "- Month\n",
    "- num_oscars_won\n",
    "- Countries (somehow)\n",
    "- Runtime\n",
    "- averageRating\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "425b67c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import statsmodels.formula.api as smf\n",
    "import networkx as nx\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def get_columns(Name, df, col):\n",
    "        out = df[df['Wikipedia ID']==Name][col].values[0]\n",
    "        return out\n",
    "\n",
    "def normalize(df, var):\n",
    "    return (df[var] - df[var].mean())/df[var].std()\n",
    "\n",
    "\n",
    "def analyse(df, dependent_var, matching_vars, independent_var, row_id_index):\n",
    "    df_matching = df.copy(deep=True).dropna(subset=matching_vars + [dependent_var, independent_var])\n",
    "  \n",
    "    for v in matching_vars:\n",
    "        df_matching[v] = normalize(df_matching, v)\n",
    "        df_matching[v] = df_matching[v].astype(float)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # First try without genres and countries\n",
    "    \n",
    "    mod = smf.logit(formula=f'{dependent_var} ~  {\" + \".join(matching_vars)}', data=df_matching)\n",
    "    res = mod.fit(maxiter=1000)\n",
    "    df_matching['Propensity_score'] = res.predict()\n",
    "\n",
    "    #display(df_matching)\n",
    "\n",
    "    # We start by creating the two groups\n",
    "    treatment_group = df_matching[df_matching[dependent_var]==1]\n",
    "    control_group = df_matching[df_matching[dependent_var]==0]\n",
    "\n",
    "    # We print the number of element in each group to check that their sum is 1538 and make sure that our matching has\n",
    "    # the same size as the smallest of the two groups (sanity check)\n",
    "    print(len(treatment_group), len(control_group))\n",
    "\n",
    "\n",
    "    G = nx.Graph()\n",
    "\n",
    "    # Add nodes for each paper in the treatment and control groups\n",
    "    G.add_nodes_from(treatment_group[row_id_index], bipartite=0)\n",
    "    G.add_nodes_from(control_group[row_id_index], bipartite=1)\n",
    "\n",
    "    # Calculate dissimilarity scores using vectorization\n",
    "    treatment_scores = np.array(treatment_group['Propensity_score'])\n",
    "    control_scores = np.array(control_group['Propensity_score'])\n",
    "\n",
    "    dissimilarity_scores = np.abs(treatment_scores[:, None] - control_scores)\n",
    "\n",
    "    start = time.time()\n",
    "\n",
    "    for i, t_node in enumerate(treatment_group[row_id_index]):\n",
    "        for j, c_node in enumerate(control_group[row_id_index]):\n",
    "            G.add_edge(t_node, c_node, weight=dissimilarity_scores[i, j])\n",
    "\n",
    "        \n",
    "    end = time.time()\n",
    "\n",
    "    print(f'Time : {end-start}')\n",
    "    # This function is to help us print the final dataframe (sanity check)\n",
    "    \n",
    "    col = 'Propensity_score'\n",
    "\n",
    "    # Perform minimum weight full matching\n",
    "    matched_pairs = nx.bipartite.minimum_weight_full_matching(G, weight='weight', top_nodes=treatment_group[row_id_index])\n",
    "    #matched_pairs = nx.max_weight_matching(G)\n",
    "\n",
    "    # The matching function from Networkx gives a symmetric dictionary (2 times too long), so we filter it here\n",
    "    filtered_edges = dict([(u, v) for u, v in matched_pairs.items() if G.nodes[u]['bipartite'] == 0 and G.nodes[v]['bipartite'] == 1])\n",
    "\n",
    "    # Create the sanity check dataframe (shows score and track)\n",
    "    df_check_matched = pd.DataFrame([(u, v, \n",
    "                                get_columns(u, treatment_group, col),\n",
    "                                get_columns(v, control_group, col),\n",
    "                            ) \n",
    "                            for u, v in filtered_edges.items()], \n",
    "                            columns=['Name_t', 'Name_c', col + ' u', col + ' v'])\n",
    "    \n",
    "    df_check_matched['matching_value'] = abs(df_check_matched['Propensity_score u']-df_check_matched['Propensity_score v'])\n",
    "    \n",
    "    df_check_matched = df_check_matched[df_check_matched['matching_value'] < 0.0001]\n",
    "\n",
    "    # Create the simple dataframe with matched papers\n",
    "    df_matched = df_check_matched[['Name_t', 'Name_c']]\n",
    "    \n",
    "    \n",
    "\n",
    "    #display(df_check_matched)\n",
    "\n",
    "    #print(len(df_check_matched[df_check_matched['track u'] != df_check_matched['track v']]))\n",
    "    df_matched_treatment = df_matching[(df_matching[dependent_var] == 1) & \n",
    "                                    (df_matching[row_id_index].isin(df_matched['Name_t']))]\n",
    "\n",
    "    df_matched_control = df_matching[(df_matching[dependent_var] == 0) & \n",
    "                                    (df_matching[row_id_index].isin(df_matched['Name_c']))]\n",
    "\n",
    "\n",
    "    #display(df_matched_treatment)\n",
    "\n",
    "    paired_ttest = smf.ols(formula=f'{independent_var} ~ {dependent_var}', data=pd.concat([df_matched_treatment, \n",
    "                                                                                    df_matched_control])).fit()\n",
    "    print(f'Test for {independent_var} ~ {dependent_var}')\n",
    "    print('')\n",
    "    print(paired_ttest.summary())\n",
    "    print('')\n",
    "    \n",
    "    return df_matched_treatment, df_matched_control\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "058fa774",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#matching_vars = ['Year', 'Month', 'averageRating', 'num_oscars_won', 'Runtime']\n",
    "#_ = analyse(df_time_stamps, 'is_first_day', matching_vars, 'Box_office', 'Wikipedia ID')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "912fb47a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.251860\n",
      "         Iterations 64\n",
      "559 7169\n",
      "Time : 2.7735321521759033\n",
      "Test for Box_office ~ is_month\n",
      "\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:             Box_office   R-squared:                       0.017\n",
      "Model:                            OLS   Adj. R-squared:                  0.016\n",
      "Method:                 Least Squares   F-statistic:                     18.45\n",
      "Date:                Mon, 27 Nov 2023   Prob (F-statistic):           1.90e-05\n",
      "Time:                        11:38:21   Log-Likelihood:                -21789.\n",
      "No. Observations:                1086   AIC:                         4.358e+04\n",
      "Df Residuals:                    1084   BIC:                         4.359e+04\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept   4.601e+07   5.37e+06      8.562      0.000    3.55e+07    5.66e+07\n",
      "is_month    3.265e+07    7.6e+06      4.296      0.000    1.77e+07    4.76e+07\n",
      "==============================================================================\n",
      "Omnibus:                      986.751   Durbin-Watson:                   2.066\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            30634.887\n",
      "Skew:                           4.223   Prob(JB):                         0.00\n",
      "Kurtosis:                      27.610   Cond. No.                         2.62\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#df_time_stamps['is_first_weekday'] = (df_time_stamps['Weekday Name'] == 'Friday').astype(int)\n",
    "#analyse(df_time_stamps, 'is_first_weekday', matching_vars, 'Box_office', 'Wikipedia ID')\n",
    "\n",
    "matching_vars = ['Year', 'averageRating', 'num_oscars_won', 'Runtime', 'Day', 'Weekday']\n",
    "matching_vars = matching_vars + [genre.replace(' ', '_').replace('-','_') + '_onehot' for genre in top_genres] \n",
    "matching_vars = matching_vars + [country.replace(' ', '_').replace('-','_') + '_onehot' for country in top_countries]\n",
    "matching_vars = matching_vars + [lang.replace(' ', '_').replace('-','_') + '_onehot' for lang in top_languages]\n",
    "\n",
    "\n",
    "df_time_stamps['is_month'] = (df_time_stamps['Month'] == 7).astype(int)\n",
    "df_matched_treatement, df_matched_control = analyse(df_time_stamps, 'is_month', matching_vars, 'Box_office', 'Wikipedia ID')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3a295ba3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.184622\n",
      "         Iterations 34\n",
      "359 7369\n",
      "Time : 1.8492610454559326\n",
      "Test for Box_office ~ is_first_day\n",
      "\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:             Box_office   R-squared:                       0.001\n",
      "Model:                            OLS   Adj. R-squared:                 -0.000\n",
      "Method:                 Least Squares   F-statistic:                    0.9609\n",
      "Date:                Mon, 27 Nov 2023   Prob (F-statistic):              0.327\n",
      "Time:                        11:38:26   Log-Likelihood:                -13843.\n",
      "No. Observations:                 698   AIC:                         2.769e+04\n",
      "Df Residuals:                     696   BIC:                         2.770e+04\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "================================================================================\n",
      "                   coef    std err          t      P>|t|      [0.025      0.975]\n",
      "--------------------------------------------------------------------------------\n",
      "Intercept     4.241e+07   5.32e+06      7.970      0.000     3.2e+07    5.29e+07\n",
      "is_first_day -7.376e+06   7.52e+06     -0.980      0.327   -2.22e+07     7.4e+06\n",
      "==============================================================================\n",
      "Omnibus:                      789.396   Durbin-Watson:                   2.031\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            47264.655\n",
      "Skew:                           5.542   Prob(JB):                         0.00\n",
      "Kurtosis:                      41.759   Cond. No.                         2.62\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "matching_vars = ['Year', 'averageRating', 'num_oscars_won', 'Runtime', 'Month', 'Weekday'] \n",
    "matching_vars = matching_vars + [genre.replace(' ', '_').replace('-','_') + '_onehot' for genre in top_genres] \n",
    "matching_vars = matching_vars + [country.replace(' ', '_').replace('-','_') + '_onehot' for country in top_countries]\n",
    "matching_vars = matching_vars + [lang.replace(' ', '_').replace('-','_') + '_onehot' for lang in top_languages]\n",
    "\n",
    "\n",
    "df_matched_treatement, df_matched_control = analyse(df_time_stamps, 'is_first_day', matching_vars, 'Box_office', 'Wikipedia ID')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0c963a09",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.194434\n",
      "         Iterations 7\n",
      "387 7341\n",
      "Time : 2.0197861194610596\n",
      "Test for Box_office ~ is_friday\n",
      "\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:             Box_office   R-squared:                       0.006\n",
      "Model:                            OLS   Adj. R-squared:                  0.005\n",
      "Method:                 Least Squares   F-statistic:                     4.697\n",
      "Date:                Mon, 27 Nov 2023   Prob (F-statistic):             0.0305\n",
      "Time:                        11:38:31   Log-Likelihood:                -15205.\n",
      "No. Observations:                 750   AIC:                         3.041e+04\n",
      "Df Residuals:                     748   BIC:                         3.042e+04\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept   6.473e+07   7.97e+06      8.118      0.000    4.91e+07    8.04e+07\n",
      "is_friday   2.444e+07   1.13e+07      2.167      0.031     2.3e+06    4.66e+07\n",
      "==============================================================================\n",
      "Omnibus:                      685.214   Durbin-Watson:                   2.046\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            20229.263\n",
      "Skew:                           4.163   Prob(JB):                         0.00\n",
      "Kurtosis:                      27.042   Cond. No.                         2.62\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_time_stamps['is_friday'] = (df_time_stamps['Weekday Name'] == 'Monday').astype(int)\n",
    "\n",
    "matching_vars = ['Year', 'averageRating', 'num_oscars_won', 'Runtime', 'Month', 'Day'] \n",
    "matching_vars = matching_vars + [genre.replace(' ', '_').replace('-','_') + '_onehot' for genre in top_genres] \n",
    "matching_vars = matching_vars + [country.replace(' ', '_').replace('-','_') + '_onehot' for country in top_countries]\n",
    "matching_vars = matching_vars + [lang.replace(' ', '_').replace('-','_') + '_onehot' for lang in top_languages]\n",
    "\n",
    "\n",
    "df_matched_treatement, df_matched_control = analyse(df_time_stamps, 'is_friday', matching_vars, 'Box_office', 'Wikipedia ID')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3ca67bff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.295320\n",
      "         Iterations 7\n",
      "686 7042\n",
      "Time : 3.4404830932617188\n",
      "Test for won_oscar ~ is_month\n",
      "\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:              won_oscar   R-squared:                       0.002\n",
      "Model:                            OLS   Adj. R-squared:                  0.002\n",
      "Method:                 Least Squares   F-statistic:                     3.029\n",
      "Date:                Mon, 27 Nov 2023   Prob (F-statistic):             0.0820\n",
      "Time:                        11:52:46   Log-Likelihood:                 38.596\n",
      "No. Observations:                1342   AIC:                            -73.19\n",
      "Df Residuals:                    1340   BIC:                            -62.79\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept      0.0477      0.009      5.250      0.000       0.030       0.066\n",
      "is_month       0.0224      0.013      1.740      0.082      -0.003       0.048\n",
      "==============================================================================\n",
      "Omnibus:                     1024.819   Durbin-Watson:                   1.995\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            11166.755\n",
      "Skew:                           3.736   Prob(JB):                         0.00\n",
      "Kurtosis:                      14.995   Cond. No.                         2.62\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_time_stamps['won_oscar'] = (df_time_stamps['num_oscars_won'] > 0).astype(int)\n",
    "df_time_stamps['is_month'] = (df_time_stamps['Month'] == 8).astype(int)\n",
    "\n",
    "\n",
    "matching_vars = ['Year', 'averageRating', 'Runtime', 'Day', 'Weekday', 'Box_office'] \n",
    "matching_vars = matching_vars + [genre.replace(' ', '_').replace('-','_') + '_onehot' for genre in top_genres] \n",
    "matching_vars = matching_vars + [country.replace(' ', '_').replace('-','_') + '_onehot' for country in top_countries]\n",
    "matching_vars = matching_vars + [lang.replace(' ', '_').replace('-','_') + '_onehot' for lang in top_languages]\n",
    "\n",
    "\n",
    "df_matched_treatement, df_matched_control = analyse(df_time_stamps, 'is_month', matching_vars, 'won_oscar', 'Wikipedia ID')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd8f70ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
