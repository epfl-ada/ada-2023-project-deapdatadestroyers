{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5adf6e86-dd91-4f02-890b-7ce1a830460e",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 1. Loading and Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2c9c6f7-8817-4f97-8bff-cc6f99f0219e",
   "metadata": {},
   "source": [
    "## 1.1 Import libraries and python files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74b9eb89-c20a-48e6-9e20-941c6f582218",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#import useful libraries \n",
    "import json\n",
    "import sys\n",
    "import requests\n",
    "import calendar\n",
    "import scipy\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm \n",
    "import statsmodels.formula.api as smf\n",
    "import seaborn as sbn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from matplotlib.colors import LogNorm, Normalize\n",
    "from sklearn.preprocessing import normalize\n",
    "from datetime import datetime\n",
    "%matplotlib inline \n",
    "\n",
    "# Import functions helper and loading functions\n",
    "from data_loader import *\n",
    "from helper_functions import *\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "##link to the datasets\n",
    "## https://www.cs.cmu.edu/~ark/personas/\n",
    "##https://www.kaggle.com/datasets/rounakbanik/the-movies-dataset?resource=download&select=movies_metadata.csv\n",
    "##https://www.kaggle.com/datasets/ashirwadsangwan/imdb-dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f542fa64-b706-4caa-ab84-613bb9229da4",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## 1.2 Load the different datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a7b84a4a-1ab6-451c-b7c9-e7bb3b96e077",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "##load datasets from CMU dataset\n",
    "df_character = load_character().copy()\n",
    "df_movie = load_movie().copy()\n",
    "df_name_cluster = load_name_cluster().copy()\n",
    "df_summary = load_plot_summary().copy()\n",
    "df_tropes_cluster = load_tropes_cluster().copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b736a777",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Replace 'id-translation.wikidata.json' with the path to your JSON file\n",
    "file_path = 'id-translation.wikidata.json'\n",
    "\n",
    "# Load the JSON file into a DataFrame\n",
    "df_id_translation = pd.read_json(file_path, orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "958e44bb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Small cleanup\n",
    "df_id_translation = df_id_translation.dropna(subset=['Freebase ID'])\n",
    "df_id_translation.drop_duplicates(subset=['Freebase ID'], keep='first', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "67b2a9d1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# df_movie will be the reference dataframe. After being completed with additional datasets, it must never be modified\n",
    "df_movie = pd.merge(df_movie, df_id_translation, on='Freebase ID', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8180483b-7664-459f-84dd-5d080744699d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The percentage of missing values in Year is 8.444%.\n",
      "The percentage of missing values in Month is 51.832%.\n",
      "The percentage of missing values in Box office is 89.722%.\n",
      "The percentage of missing values in Runtime is 25.018%.\n",
      "The percentage of missing values in tconst is 9.769%.\n"
     ]
    }
   ],
   "source": [
    "#compute percentage of missing values for df_movie\n",
    "values = ['Year', 'Month', 'Box office', 'Runtime', 'tconst']\n",
    "\n",
    "def compute_missing_values(df, values):\n",
    "    for variable in values :\n",
    "        percentage_missing_values = (df[variable].isna().sum()/len(df[variable]))*100\n",
    "        print(f\"The percentage of missing values in {variable} is {format(percentage_missing_values, '.3f')}%.\")\n",
    "\n",
    "    \n",
    "compute_missing_values(df_movie, values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d470997-3782-42f6-ad5c-9c061d37a74b",
   "metadata": {
    "tags": []
   },
   "source": [
    "As we can see, a lot of 'Box office' data is missing. We should add some other database to try to reduce the missing data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b92c14c-f7a3-4b37-8955-48740aa1d7a3",
   "metadata": {},
   "source": [
    "## 1.3 Load addtionnal datasets and merge what we need "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "23805801",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#load imdb dataset (from kaggle)\n",
    "df_imdb_movie = load_movie_imdb_kaggle()\n",
    "df_imdb_rating = load_rating_imdb_kaggle() \n",
    "\n",
    "#merge movies with rating \n",
    "df_movie_rating = pd.merge(df_imdb_movie, df_imdb_rating, on='tconst', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "153d0412",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#merge CMU dataset with IMDB dataset\n",
    "df_movie = pd.merge(df_movie, df_movie_rating[['tconst', 'averageRating', 'numVotes']], on=['tconst'], how='left')\n",
    "#display(df_movie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0fbe01e3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The percentage of missing values in averageRating is 31.271%.\n",
      "The percentage of missing values in numVotes is 31.271%.\n",
      "The number of movies with missing values for 'averageRating' and 'numVotes' is 25561.\n"
     ]
    }
   ],
   "source": [
    "# missing Rating values\n",
    "values = ['averageRating', 'numVotes']\n",
    "\n",
    "compute_missing_values(df_movie, values)\n",
    "print(f\"The number of movies with missing values for 'averageRating' and 'numVotes' is {df_movie['averageRating'].isna().sum()}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1fbba358",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## load kaggle movie metadata\n",
    "df_kaggle_movie = load_movie_kaggle()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5ddefe3a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Wikipedia ID</th>\n",
       "      <th>Freebase ID</th>\n",
       "      <th>Name</th>\n",
       "      <th>Release date</th>\n",
       "      <th>Box office</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Languages (Freebase ID:name tuples)</th>\n",
       "      <th>Countries (Freebase ID:name tuples)</th>\n",
       "      <th>genres (Freebase ID:name tuples)</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>tconst</th>\n",
       "      <th>averageRating</th>\n",
       "      <th>numVotes</th>\n",
       "      <th>Month_df2</th>\n",
       "      <th>Day_df2</th>\n",
       "      <th>budget</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>975900</td>\n",
       "      <td>/m/03vyhn</td>\n",
       "      <td>Ghosts of Mars</td>\n",
       "      <td>2001-08-24</td>\n",
       "      <td>14010832.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>{\"/m/02h40lc\": \"English Language\"}</td>\n",
       "      <td>{\"/m/09c7w0\": \"United States of America\"}</td>\n",
       "      <td>{\"/m/01jfsb\": \"Thriller\", \"/m/06n90\": \"Science...</td>\n",
       "      <td>2001</td>\n",
       "      <td>8</td>\n",
       "      <td>24</td>\n",
       "      <td>tt0228333</td>\n",
       "      <td>4.9</td>\n",
       "      <td>56854.0</td>\n",
       "      <td>8</td>\n",
       "      <td>24</td>\n",
       "      <td>28000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3196793</td>\n",
       "      <td>/m/08yl5d</td>\n",
       "      <td>Getting Away with Murder: The JonBen√©t Ramsey ...</td>\n",
       "      <td>2000-02-16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>95.0</td>\n",
       "      <td>{\"/m/02h40lc\": \"English Language\"}</td>\n",
       "      <td>{\"/m/09c7w0\": \"United States of America\"}</td>\n",
       "      <td>{\"/m/02n4kr\": \"Mystery\", \"/m/03bxz7\": \"Biograp...</td>\n",
       "      <td>2000</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>tt0245916</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28463795</td>\n",
       "      <td>/m/0crgdbh</td>\n",
       "      <td>Brun bitter</td>\n",
       "      <td>1988</td>\n",
       "      <td>NaN</td>\n",
       "      <td>83.0</td>\n",
       "      <td>{\"/m/05f_3\": \"Norwegian Language\"}</td>\n",
       "      <td>{\"/m/05b4w\": \"Norway\"}</td>\n",
       "      <td>{\"/m/0lsxr\": \"Crime Fiction\", \"/m/07s9rl0\": \"D...</td>\n",
       "      <td>1988</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>tt0094806</td>\n",
       "      <td>5.6</td>\n",
       "      <td>40.0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9363483</td>\n",
       "      <td>/m/0285_cd</td>\n",
       "      <td>White Of The Eye</td>\n",
       "      <td>1987</td>\n",
       "      <td>NaN</td>\n",
       "      <td>110.0</td>\n",
       "      <td>{\"/m/02h40lc\": \"English Language\"}</td>\n",
       "      <td>{\"/m/07ssc\": \"United Kingdom\"}</td>\n",
       "      <td>{\"/m/01jfsb\": \"Thriller\", \"/m/0glj9q\": \"Erotic...</td>\n",
       "      <td>1987</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>tt0094320</td>\n",
       "      <td>6.1</td>\n",
       "      <td>2888.0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>261236</td>\n",
       "      <td>/m/01mrr1</td>\n",
       "      <td>A Woman in Flames</td>\n",
       "      <td>1983</td>\n",
       "      <td>NaN</td>\n",
       "      <td>106.0</td>\n",
       "      <td>{\"/m/04306rv\": \"German Language\"}</td>\n",
       "      <td>{\"/m/0345h\": \"Germany\"}</td>\n",
       "      <td>{\"/m/07s9rl0\": \"Drama\"}</td>\n",
       "      <td>1983</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>tt0083949</td>\n",
       "      <td>6.0</td>\n",
       "      <td>621.0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81752</th>\n",
       "      <td>35228177</td>\n",
       "      <td>/m/0j7hxnt</td>\n",
       "      <td>Mermaids: The Body Found</td>\n",
       "      <td>2011-03-19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>120.0</td>\n",
       "      <td>{\"/m/02h40lc\": \"English Language\"}</td>\n",
       "      <td>{\"/m/09c7w0\": \"United States of America\"}</td>\n",
       "      <td>{\"/m/07s9rl0\": \"Drama\"}</td>\n",
       "      <td>2011</td>\n",
       "      <td>3</td>\n",
       "      <td>19</td>\n",
       "      <td>tt1816585</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81753</th>\n",
       "      <td>34980460</td>\n",
       "      <td>/m/0g4pl34</td>\n",
       "      <td>Knuckle</td>\n",
       "      <td>2011-01-21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>96.0</td>\n",
       "      <td>{\"/m/02h40lc\": \"English Language\"}</td>\n",
       "      <td>{\"/m/03rt9\": \"Ireland\", \"/m/07ssc\": \"United Ki...</td>\n",
       "      <td>{\"/m/03bxz7\": \"Biographical film\", \"/m/07s9rl0...</td>\n",
       "      <td>2011</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>tt1606259</td>\n",
       "      <td>6.8</td>\n",
       "      <td>3191.0</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81754</th>\n",
       "      <td>9971909</td>\n",
       "      <td>/m/02pygw1</td>\n",
       "      <td>Another Nice Mess</td>\n",
       "      <td>1972-09-22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>66.0</td>\n",
       "      <td>{\"/m/02h40lc\": \"English Language\"}</td>\n",
       "      <td>{\"/m/09c7w0\": \"United States of America\"}</td>\n",
       "      <td>{\"/m/06nbt\": \"Satire\", \"/m/01z4y\": \"Comedy\"}</td>\n",
       "      <td>1972</td>\n",
       "      <td>9</td>\n",
       "      <td>22</td>\n",
       "      <td>tt0362411</td>\n",
       "      <td>5.8</td>\n",
       "      <td>110.0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81755</th>\n",
       "      <td>913762</td>\n",
       "      <td>/m/03pcrp</td>\n",
       "      <td>The Super Dimension Fortress Macross II: Lover...</td>\n",
       "      <td>1992-05-21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>150.0</td>\n",
       "      <td>{\"/m/03_9r\": \"Japanese Language\"}</td>\n",
       "      <td>{\"/m/03_3d\": \"Japan\"}</td>\n",
       "      <td>{\"/m/06n90\": \"Science Fiction\", \"/m/0gw5n2f\": ...</td>\n",
       "      <td>1992</td>\n",
       "      <td>5</td>\n",
       "      <td>21</td>\n",
       "      <td>tt0113726</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81756</th>\n",
       "      <td>12476867</td>\n",
       "      <td>/m/02w7zz8</td>\n",
       "      <td>Spliced</td>\n",
       "      <td>2002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>86.0</td>\n",
       "      <td>{\"/m/02h40lc\": \"English Language\"}</td>\n",
       "      <td>{\"/m/0d060g\": \"Canada\"}</td>\n",
       "      <td>{\"/m/01jfsb\": \"Thriller\", \"/m/03npn\": \"Horror\"...</td>\n",
       "      <td>2002</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>tt0354216</td>\n",
       "      <td>4.3</td>\n",
       "      <td>1766.0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>81757 rows √ó 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Wikipedia ID Freebase ID  \\\n",
       "0            975900   /m/03vyhn   \n",
       "1           3196793   /m/08yl5d   \n",
       "2          28463795  /m/0crgdbh   \n",
       "3           9363483  /m/0285_cd   \n",
       "4            261236   /m/01mrr1   \n",
       "...             ...         ...   \n",
       "81752      35228177  /m/0j7hxnt   \n",
       "81753      34980460  /m/0g4pl34   \n",
       "81754       9971909  /m/02pygw1   \n",
       "81755        913762   /m/03pcrp   \n",
       "81756      12476867  /m/02w7zz8   \n",
       "\n",
       "                                                    Name Release date  \\\n",
       "0                                         Ghosts of Mars   2001-08-24   \n",
       "1      Getting Away with Murder: The JonBen√©t Ramsey ...   2000-02-16   \n",
       "2                                            Brun bitter         1988   \n",
       "3                                       White Of The Eye         1987   \n",
       "4                                      A Woman in Flames         1983   \n",
       "...                                                  ...          ...   \n",
       "81752                           Mermaids: The Body Found   2011-03-19   \n",
       "81753                                            Knuckle   2011-01-21   \n",
       "81754                                  Another Nice Mess   1972-09-22   \n",
       "81755  The Super Dimension Fortress Macross II: Lover...   1992-05-21   \n",
       "81756                                            Spliced         2002   \n",
       "\n",
       "       Box office  Runtime Languages (Freebase ID:name tuples)  \\\n",
       "0      14010832.0     98.0  {\"/m/02h40lc\": \"English Language\"}   \n",
       "1             NaN     95.0  {\"/m/02h40lc\": \"English Language\"}   \n",
       "2             NaN     83.0  {\"/m/05f_3\": \"Norwegian Language\"}   \n",
       "3             NaN    110.0  {\"/m/02h40lc\": \"English Language\"}   \n",
       "4             NaN    106.0   {\"/m/04306rv\": \"German Language\"}   \n",
       "...           ...      ...                                 ...   \n",
       "81752         NaN    120.0  {\"/m/02h40lc\": \"English Language\"}   \n",
       "81753         NaN     96.0  {\"/m/02h40lc\": \"English Language\"}   \n",
       "81754         NaN     66.0  {\"/m/02h40lc\": \"English Language\"}   \n",
       "81755         NaN    150.0   {\"/m/03_9r\": \"Japanese Language\"}   \n",
       "81756         NaN     86.0  {\"/m/02h40lc\": \"English Language\"}   \n",
       "\n",
       "                     Countries (Freebase ID:name tuples)  \\\n",
       "0              {\"/m/09c7w0\": \"United States of America\"}   \n",
       "1              {\"/m/09c7w0\": \"United States of America\"}   \n",
       "2                                 {\"/m/05b4w\": \"Norway\"}   \n",
       "3                         {\"/m/07ssc\": \"United Kingdom\"}   \n",
       "4                                {\"/m/0345h\": \"Germany\"}   \n",
       "...                                                  ...   \n",
       "81752          {\"/m/09c7w0\": \"United States of America\"}   \n",
       "81753  {\"/m/03rt9\": \"Ireland\", \"/m/07ssc\": \"United Ki...   \n",
       "81754          {\"/m/09c7w0\": \"United States of America\"}   \n",
       "81755                              {\"/m/03_3d\": \"Japan\"}   \n",
       "81756                            {\"/m/0d060g\": \"Canada\"}   \n",
       "\n",
       "                        genres (Freebase ID:name tuples)  Year  Month   Day  \\\n",
       "0      {\"/m/01jfsb\": \"Thriller\", \"/m/06n90\": \"Science...  2001      8    24   \n",
       "1      {\"/m/02n4kr\": \"Mystery\", \"/m/03bxz7\": \"Biograp...  2000      2    16   \n",
       "2      {\"/m/0lsxr\": \"Crime Fiction\", \"/m/07s9rl0\": \"D...  1988   <NA>  <NA>   \n",
       "3      {\"/m/01jfsb\": \"Thriller\", \"/m/0glj9q\": \"Erotic...  1987   <NA>  <NA>   \n",
       "4                                {\"/m/07s9rl0\": \"Drama\"}  1983   <NA>  <NA>   \n",
       "...                                                  ...   ...    ...   ...   \n",
       "81752                            {\"/m/07s9rl0\": \"Drama\"}  2011      3    19   \n",
       "81753  {\"/m/03bxz7\": \"Biographical film\", \"/m/07s9rl0...  2011      1    21   \n",
       "81754       {\"/m/06nbt\": \"Satire\", \"/m/01z4y\": \"Comedy\"}  1972      9    22   \n",
       "81755  {\"/m/06n90\": \"Science Fiction\", \"/m/0gw5n2f\": ...  1992      5    21   \n",
       "81756  {\"/m/01jfsb\": \"Thriller\", \"/m/03npn\": \"Horror\"...  2002   <NA>  <NA>   \n",
       "\n",
       "          tconst  averageRating  numVotes  Month_df2  Day_df2    budget  \n",
       "0      tt0228333            4.9   56854.0          8       24  28000000  \n",
       "1      tt0245916            NaN       NaN       <NA>     <NA>       NaN  \n",
       "2      tt0094806            5.6      40.0       <NA>     <NA>       NaN  \n",
       "3      tt0094320            6.1    2888.0       <NA>     <NA>       NaN  \n",
       "4      tt0083949            6.0     621.0       <NA>     <NA>       NaN  \n",
       "...          ...            ...       ...        ...      ...       ...  \n",
       "81752  tt1816585            NaN       NaN       <NA>     <NA>       NaN  \n",
       "81753  tt1606259            6.8    3191.0         12        9       NaN  \n",
       "81754  tt0362411            5.8     110.0       <NA>     <NA>       NaN  \n",
       "81755  tt0113726            NaN       NaN       <NA>     <NA>       NaN  \n",
       "81756  tt0354216            4.3    1766.0       <NA>     <NA>       NaN  \n",
       "\n",
       "[81757 rows x 18 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#merge the datasets on the 'Name' column\n",
    "#df_movie = df_movie.merge(df_kaggle_movie[['Name', 'Year', 'Month', 'Day']], on=['Name', 'Year'], how='left', suffixes=('', '_df2'))\n",
    "df_movie = df_movie.merge(df_kaggle_movie[['Name', 'Year', 'tconst', 'Month', 'Day', 'budget']], on=['Name', 'Year','tconst'], how='left', suffixes=('', '_df2'))\n",
    "df_movie.loc[df_movie['budget'] == '0', 'budget'] = np.nan\n",
    "display(df_movie)\n",
    "\n",
    "df_movie['budget'] = pd.to_numeric(df_movie['budget'], errors='coerce')\n",
    "\n",
    "\n",
    "#print(len(df_movie[(df_movie['budget'] >0) & \n",
    "#                          (df_movie['Box office'].astype(float)>0)]  ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5995d12b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#use 'combine_first' to fill in the 'Box office' values from df_kaggle_movie where they are NaN in df_movie\n",
    "df_movie['Month'] = df_movie['Month'].combine_first(df_movie['Month_df2'])\n",
    "df_movie['Day'] = df_movie['Day'].combine_first(df_movie['Day_df2'])\n",
    "\n",
    "#drop the extra 'Box office' column from df_kaggle_movie\n",
    "df_movie.drop('Month_df2', axis=1, inplace=True)\n",
    "df_movie.drop('Day_df2', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9ae92096",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The percentage of missing values in Year is 8.442%.\n",
      "The percentage of missing values in Month is 42.891%.\n",
      "The percentage of missing values in Box office is 89.721%.\n",
      "The percentage of missing values in Runtime is 25.014%.\n",
      "The percentage of missing values in tconst is 9.767%.\n",
      "The percentage of missing values in budget is 93.103%.\n"
     ]
    }
   ],
   "source": [
    "values = ['Year', 'Month', 'Box office', 'Runtime', 'tconst', 'budget']\n",
    "compute_missing_values(df_movie, values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "103d62c2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#load oscar reward dataset\n",
    "df_oscar = load_oscar_winner()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2da51686",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#filter the dataframe to only include rows where 'winner' is True\n",
    "df_winner_movie = df_oscar[df_oscar['winner'] == True]\n",
    "\n",
    "#group by the movie name and count the winners time\n",
    "df_winner_movie = df_winner_movie.groupby('Name').agg(\n",
    "    num_oscars_won=pd.NamedAgg(column='winner', aggfunc='size'),\n",
    "    years_won=pd.NamedAgg(column='year_ceremony', aggfunc=lambda x: list(x))\n",
    ").reset_index()\n",
    "\n",
    "#sort the movies by oscars won\n",
    "df_oscar_wins = df_winner_movie.sort_values(by='num_oscars_won', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "43d1d1a9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#merge CUM and oscars awards dataset\n",
    "df_movie = pd.merge(df_movie, df_oscar_wins, left_on='Name', right_on='Name', how='left')\n",
    "\n",
    "#replace NaN values in 'num_oscars_won' with 0 for movies that didn't win any oscars\n",
    "df_movie['num_oscars_won'].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ead13e05",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The percentage of movies having won an oscar is 1.896%.\n"
     ]
    }
   ],
   "source": [
    "percentage_oascar_movies = ((df_movie['num_oscars_won']!=0).sum()/len(df_movie['num_oscars_won']))*100\n",
    "print(f\"The percentage of movies having won an oscar is {format(percentage_oascar_movies, '.3f')}%.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "454466d2-0de1-45e3-a007-f9219a8c9508",
   "metadata": {},
   "source": [
    "## 1.4 Cleanup of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9551a8e3-82cc-41b8-b2c1-76fd147f7167",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Drop the row with 'Year' smaller than 1800 as we have seen somme erronous movie before and there is too few movies after 2014.\n",
    "df_movie = df_movie[(df_movie['Year'] >= 1800) & (df_movie['Year'] <= 2013)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ed2a5df-8922-4d9c-81a3-c0879cfcce4c",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 2. First day of the month"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "611001d6-0256-4e6b-93cd-40287b440450",
   "metadata": {},
   "source": [
    "Let's try to prove that releasing on the 1st day of the month is a mistake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a40a8f61",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_time_stamps = get_time_stamps_df(df_movie)\n",
    "\n",
    "df_time_stamps.rename(columns={'Countries (Freebase ID:name tuples)' : 'Countries',\n",
    "                                'Box office' : 'Box_office',\n",
    "                              'genres (Freebase ID:name tuples)' : 'Genres',\n",
    "                               'Languages (Freebase ID:name tuples)' : 'Languages'\n",
    "                              }, errors=\"raise\", inplace=True)\n",
    "\n",
    "\n",
    "df_time_stamps['Genres']= df_time_stamps['Genres'].apply(lambda x : list(json.loads(x).values()))\n",
    "df_time_stamps['Countries']= df_time_stamps['Countries'].apply(lambda x : list(json.loads(x).values()))\n",
    "df_time_stamps['Languages']= df_time_stamps['Languages'].apply(lambda x : list(json.loads(x).values()))\n",
    "\n",
    "\n",
    "\n",
    "df_time_stamps.drop(labels=['Freebase ID', 'Release date', 'tconst'], axis=1, inplace=True)\n",
    "#display(df_time_stamps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e1d67833",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_genre_list = df_time_stamps.copy(deep=True)\n",
    "genres = get_values_column_of_list(df_genre_list, 'Genres')\n",
    "sorted_genres = sorted(genres.items(), key=lambda x:x[1], reverse=True)\n",
    "top_genres = [genre[0] for genre in sorted_genres[:5]]\n",
    "\n",
    "df_country_list = df_time_stamps.copy(deep=True)\n",
    "countries = get_values_column_of_list(df_country_list, 'Countries')\n",
    "sorted_countries = sorted(countries.items(), key=lambda x:x[1], reverse=True)\n",
    "top_countries = [country[0] for country in sorted_countries[:5]]\n",
    "\n",
    "df_language_list = df_time_stamps.copy(deep=True)\n",
    "languages = get_values_column_of_list(df_language_list, 'Languages')\n",
    "sorted_languages = sorted(languages.items(), key=lambda x:x[1], reverse=True)\n",
    "top_languages = [language[0] for language in sorted_languages[:3]]\n",
    "\n",
    "\n",
    "def add_dummies(df, var, top_dummies):\n",
    "    df_dummies = df.copy(deep=True)\n",
    "\n",
    "    for value in top_dummies:\n",
    "        df_dummies[str(value).replace(' ', '_').replace('-','_') + '_onehot'] = df_dummies[var].apply(lambda x: 1 if value in x else 0)\n",
    "    df_dummies.drop(labels=var, axis=1, inplace=True)\n",
    "    return df_dummies\n",
    "\n",
    "df_time_stamps = add_dummies(df_time_stamps, 'Genres', top_genres)\n",
    "df_time_stamps = add_dummies(df_time_stamps, 'Countries', top_countries)\n",
    "df_time_stamps = add_dummies(df_time_stamps, 'Languages', top_languages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "384ec293",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Wikipedia ID</th>\n",
       "      <th>Name</th>\n",
       "      <th>Box_office</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>averageRating</th>\n",
       "      <th>numVotes</th>\n",
       "      <th>budget</th>\n",
       "      <th>...</th>\n",
       "      <th>Black_and_white_onehot</th>\n",
       "      <th>Thriller_onehot</th>\n",
       "      <th>United_States_of_America_onehot</th>\n",
       "      <th>United_Kingdom_onehot</th>\n",
       "      <th>India_onehot</th>\n",
       "      <th>France_onehot</th>\n",
       "      <th>Japan_onehot</th>\n",
       "      <th>English_Language_onehot</th>\n",
       "      <th>French_Language_onehot</th>\n",
       "      <th>Silent_film_onehot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>975900</td>\n",
       "      <td>Ghosts of Mars</td>\n",
       "      <td>14010832.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>2001</td>\n",
       "      <td>8</td>\n",
       "      <td>24</td>\n",
       "      <td>4.9</td>\n",
       "      <td>56854.0</td>\n",
       "      <td>28000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3196793</td>\n",
       "      <td>Getting Away with Murder: The JonBen√©t Ramsey ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>95.0</td>\n",
       "      <td>2000</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>13696889</td>\n",
       "      <td>The Gangsters</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1913</td>\n",
       "      <td>5</td>\n",
       "      <td>29</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10408933</td>\n",
       "      <td>Alexander's Ragtime Band</td>\n",
       "      <td>3600000.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>1938</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>6.8</td>\n",
       "      <td>2265.0</td>\n",
       "      <td>2000000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>6631279</td>\n",
       "      <td>Little city</td>\n",
       "      <td>NaN</td>\n",
       "      <td>93.0</td>\n",
       "      <td>1997</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5.8</td>\n",
       "      <td>1129.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81751</th>\n",
       "      <td>32468537</td>\n",
       "      <td>Shadow Boxing 2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>132.0</td>\n",
       "      <td>2007</td>\n",
       "      <td>10</td>\n",
       "      <td>18</td>\n",
       "      <td>5.8</td>\n",
       "      <td>1066.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81752</th>\n",
       "      <td>35228177</td>\n",
       "      <td>Mermaids: The Body Found</td>\n",
       "      <td>NaN</td>\n",
       "      <td>120.0</td>\n",
       "      <td>2011</td>\n",
       "      <td>3</td>\n",
       "      <td>19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81753</th>\n",
       "      <td>34980460</td>\n",
       "      <td>Knuckle</td>\n",
       "      <td>NaN</td>\n",
       "      <td>96.0</td>\n",
       "      <td>2011</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>6.8</td>\n",
       "      <td>3191.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81754</th>\n",
       "      <td>9971909</td>\n",
       "      <td>Another Nice Mess</td>\n",
       "      <td>NaN</td>\n",
       "      <td>66.0</td>\n",
       "      <td>1972</td>\n",
       "      <td>9</td>\n",
       "      <td>22</td>\n",
       "      <td>5.8</td>\n",
       "      <td>110.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81755</th>\n",
       "      <td>913762</td>\n",
       "      <td>The Super Dimension Fortress Macross II: Lover...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>150.0</td>\n",
       "      <td>1992</td>\n",
       "      <td>5</td>\n",
       "      <td>21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>46680 rows √ó 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Wikipedia ID                                               Name  \\\n",
       "0            975900                                     Ghosts of Mars   \n",
       "1           3196793  Getting Away with Murder: The JonBen√©t Ramsey ...   \n",
       "5          13696889                                      The Gangsters   \n",
       "7          10408933                           Alexander's Ragtime Band   \n",
       "12          6631279                                        Little city   \n",
       "...             ...                                                ...   \n",
       "81751      32468537                                    Shadow Boxing 2   \n",
       "81752      35228177                           Mermaids: The Body Found   \n",
       "81753      34980460                                            Knuckle   \n",
       "81754       9971909                                  Another Nice Mess   \n",
       "81755        913762  The Super Dimension Fortress Macross II: Lover...   \n",
       "\n",
       "       Box_office  Runtime  Year  Month  Day  averageRating  numVotes  \\\n",
       "0      14010832.0     98.0  2001      8   24            4.9   56854.0   \n",
       "1             NaN     95.0  2000      2   16            NaN       NaN   \n",
       "5             NaN     35.0  1913      5   29            NaN       NaN   \n",
       "7       3600000.0    106.0  1938      8   16            6.8    2265.0   \n",
       "12            NaN     93.0  1997      4    4            5.8    1129.0   \n",
       "...           ...      ...   ...    ...  ...            ...       ...   \n",
       "81751         NaN    132.0  2007     10   18            5.8    1066.0   \n",
       "81752         NaN    120.0  2011      3   19            NaN       NaN   \n",
       "81753         NaN     96.0  2011      1   21            6.8    3191.0   \n",
       "81754         NaN     66.0  1972      9   22            5.8     110.0   \n",
       "81755         NaN    150.0  1992      5   21            NaN       NaN   \n",
       "\n",
       "           budget  ...  Black_and_white_onehot Thriller_onehot  \\\n",
       "0      28000000.0  ...                       0               1   \n",
       "1             NaN  ...                       0               0   \n",
       "5             NaN  ...                       1               0   \n",
       "7       2000000.0  ...                       1               0   \n",
       "12            NaN  ...                       0               0   \n",
       "...           ...  ...                     ...             ...   \n",
       "81751         NaN  ...                       0               0   \n",
       "81752         NaN  ...                       0               0   \n",
       "81753         NaN  ...                       0               0   \n",
       "81754         NaN  ...                       0               0   \n",
       "81755         NaN  ...                       0               0   \n",
       "\n",
       "       United_States_of_America_onehot United_Kingdom_onehot  India_onehot  \\\n",
       "0                                    1                     0             0   \n",
       "1                                    1                     0             0   \n",
       "5                                    1                     0             0   \n",
       "7                                    1                     0             0   \n",
       "12                                   1                     0             0   \n",
       "...                                ...                   ...           ...   \n",
       "81751                                0                     0             0   \n",
       "81752                                1                     0             0   \n",
       "81753                                0                     1             0   \n",
       "81754                                1                     0             0   \n",
       "81755                                0                     0             0   \n",
       "\n",
       "       France_onehot  Japan_onehot  English_Language_onehot  \\\n",
       "0                  0             0                        1   \n",
       "1                  0             0                        1   \n",
       "5                  0             0                        1   \n",
       "7                  0             0                        1   \n",
       "12                 0             0                        1   \n",
       "...              ...           ...                      ...   \n",
       "81751              0             0                        1   \n",
       "81752              0             0                        1   \n",
       "81753              0             0                        1   \n",
       "81754              0             0                        1   \n",
       "81755              0             1                        0   \n",
       "\n",
       "       French_Language_onehot  Silent_film_onehot  \n",
       "0                           0                   0  \n",
       "1                           0                   0  \n",
       "5                           0                   1  \n",
       "7                           0                   0  \n",
       "12                          0                   0  \n",
       "...                       ...                 ...  \n",
       "81751                       0                   0  \n",
       "81752                       0                   0  \n",
       "81753                       0                   0  \n",
       "81754                       0                   0  \n",
       "81755                       0                   0  \n",
       "\n",
       "[46680 rows x 27 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df_time_stamps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "425b67c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import statsmodels.formula.api as smf\n",
    "import networkx as nx\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def get_columns(Name, df, col):\n",
    "        out = df[df['Wikipedia ID']==Name][col].values[0]\n",
    "        return out\n",
    "\n",
    "def normalize(df, var):\n",
    "    return (df[var] - df[var].mean())/df[var].std()\n",
    "\n",
    "\n",
    "def analyse(df, dependent_var, matching_vars, independent_var, row_id_index, onehot_vars):\n",
    "    df_matching = df.copy(deep=True).dropna(subset=matching_vars + [dependent_var, independent_var] + onehot_vars)\n",
    "  \n",
    "    for v in matching_vars:\n",
    "        df_matching[v] = df_matching[v].astype(float)\n",
    "        df_matching[v] = normalize(df_matching, v)\n",
    "        \n",
    "        \n",
    "\n",
    "    \n",
    "    mod = smf.logit(formula=f'{dependent_var} ~  {\" + \".join(matching_vars + onehot_vars)}', data=df_matching)\n",
    "    res = mod.fit(maxiter=100)\n",
    "    df_matching['Propensity_score'] = res.predict()\n",
    "\n",
    "    #display(df_matching)\n",
    "\n",
    "    # We start by creating the two groups\n",
    "    treatment_group = df_matching[df_matching[dependent_var]==1]\n",
    "    control_group = df_matching[df_matching[dependent_var]==0]\n",
    "\n",
    "    # We print the number of element in each group to check that their sum is 1538 and make sure that our matching has\n",
    "    # the same size as the smallest of the two groups (sanity check)\n",
    "    print(len(treatment_group), len(control_group))\n",
    "\n",
    "\n",
    "    G = nx.Graph()\n",
    "\n",
    "    # Add nodes for each paper in the treatment and control groups\n",
    "    G.add_nodes_from(treatment_group[row_id_index], bipartite=0)\n",
    "    G.add_nodes_from(control_group[row_id_index], bipartite=1)\n",
    "\n",
    "    # Calculate dissimilarity scores using vectorization\n",
    "    treatment_scores = np.array(treatment_group['Propensity_score'])\n",
    "    control_scores = np.array(control_group['Propensity_score'])\n",
    "\n",
    "    dissimilarity_scores = np.abs(treatment_scores[:, None] - control_scores)\n",
    "\n",
    "    start = time.time()\n",
    "\n",
    "    for i, t_node in enumerate(treatment_group[row_id_index]):\n",
    "        for j, c_node in enumerate(control_group[row_id_index]):\n",
    "            G.add_edge(t_node, c_node, weight=dissimilarity_scores[i, j])\n",
    "\n",
    "        \n",
    "    end = time.time()\n",
    "\n",
    "    print(f'Time : {end-start}')\n",
    "    # This function is to help us print the final dataframe (sanity check)\n",
    "    \n",
    "    col = 'Propensity_score'\n",
    "\n",
    "    # Perform minimum weight full matching\n",
    "    matched_pairs = nx.bipartite.minimum_weight_full_matching(G, weight='weight', top_nodes=treatment_group[row_id_index])\n",
    "    #matched_pairs = nx.max_weight_matching(G)\n",
    "\n",
    "    # The matching function from Networkx gives a symmetric dictionary (2 times too long), so we filter it here\n",
    "    filtered_edges = dict([(u, v) for u, v in matched_pairs.items() if G.nodes[u]['bipartite'] == 0 and G.nodes[v]['bipartite'] == 1])\n",
    "\n",
    "    # Create the sanity check dataframe (shows score and track)\n",
    "    df_check_matched = pd.DataFrame([(u, v, \n",
    "                                get_columns(u, treatment_group, col),\n",
    "                                get_columns(v, control_group, col),\n",
    "                            ) \n",
    "                            for u, v in filtered_edges.items()], \n",
    "                            columns=['Name_t', 'Name_c', col + ' u', col + ' v'])\n",
    "    \n",
    "    df_check_matched['matching_value'] = abs(df_check_matched['Propensity_score u']-df_check_matched['Propensity_score v'])\n",
    "    \n",
    "    df_check_matched = df_check_matched[df_check_matched['matching_value'] < 0.0001]\n",
    "\n",
    "    # Create the simple dataframe with matched papers\n",
    "    df_matched = df_check_matched[['Name_t', 'Name_c']]\n",
    "    \n",
    "    \n",
    "\n",
    "    #display(df_check_matched)\n",
    "\n",
    "    #print(len(df_check_matched[df_check_matched['track u'] != df_check_matched['track v']]))\n",
    "    df_matched_treatment = df_matching[(df_matching[dependent_var] == 1) & \n",
    "                                    (df_matching[row_id_index].isin(df_matched['Name_t']))]\n",
    "\n",
    "    df_matched_control = df_matching[(df_matching[dependent_var] == 0) & \n",
    "                                    (df_matching[row_id_index].isin(df_matched['Name_c']))]\n",
    "\n",
    "\n",
    "    #display(df_matched_treatment)\n",
    "\n",
    "    paired_ttest = smf.ols(formula=f'{independent_var} ~ {dependent_var}', data=pd.concat([df_matched_treatment, \n",
    "                                                                                    df_matched_control])).fit()\n",
    "    print(f'Test for {independent_var} ~ {dependent_var}')\n",
    "    print('')\n",
    "    print(paired_ttest.summary())\n",
    "    print('')\n",
    "    \n",
    "    return df_matched_treatment, df_matched_control\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2636234c",
   "metadata": {},
   "source": [
    "We will use propensity score for the variables : \n",
    "- Genres \n",
    "- Year\n",
    "- Month\n",
    "- num_oscars_won\n",
    "- Countries \n",
    "- Runtime\n",
    "- averageRating\n",
    "- Budget\n",
    "- Month Day\n",
    "- Week Day\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "058fa774",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "onehot_vars = []\n",
    "onehot_vars = onehot_vars + [genre.replace(' ', '_').replace('-','_') + '_onehot' for genre in top_genres] \n",
    "onehot_vars = onehot_vars + [country.replace(' ', '_').replace('-','_') + '_onehot' for country in top_countries]\n",
    "#onehot_vars = onehot_vars + [lang.replace(' ', '_').replace('-','_') + '_onehot' for lang in top_languages]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "912fb47a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.262239\n",
      "         Iterations 8\n",
      "288 3393\n",
      "Time : 0.7141640186309814\n",
      "Test for Box_office ~ is_month\n",
      "\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:             Box_office   R-squared:                       0.013\n",
      "Model:                            OLS   Adj. R-squared:                  0.011\n",
      "Method:                 Least Squares   F-statistic:                     6.432\n",
      "Date:                Thu, 30 Nov 2023   Prob (F-statistic):             0.0115\n",
      "Time:                        14:15:06   Log-Likelihood:                -10010.\n",
      "No. Observations:                 496   AIC:                         2.002e+04\n",
      "Df Residuals:                     494   BIC:                         2.003e+04\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept   8.165e+07   8.96e+06      9.117      0.000    6.41e+07    9.92e+07\n",
      "is_month    3.212e+07   1.27e+07      2.536      0.012    7.24e+06     5.7e+07\n",
      "==============================================================================\n",
      "Omnibus:                      341.448   Durbin-Watson:                   2.045\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             3688.368\n",
      "Skew:                           2.964   Prob(JB):                         0.00\n",
      "Kurtosis:                      14.972   Cond. No.                         2.62\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_time_stamps['is_month'] = (df_time_stamps['Month'] == 7).astype(int)\n",
    "\n",
    "matching_vars = ['Year', 'Runtime', 'budget', 'Day']\n",
    "\n",
    "\n",
    "df_matched_treatement, df_matched_control = analyse(df_time_stamps, 'is_month', matching_vars, \n",
    "                                                    'Box_office', 'Wikipedia ID', onehot_vars)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3a295ba3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.160637\n",
      "         Iterations 60\n",
      "143 3538\n",
      "Time : 0.4260852336883545\n",
      "Test for Box_office ~ is_first_day\n",
      "\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:             Box_office   R-squared:                       0.004\n",
      "Model:                            OLS   Adj. R-squared:                  0.000\n",
      "Method:                 Least Squares   F-statistic:                     1.018\n",
      "Date:                Thu, 30 Nov 2023   Prob (F-statistic):              0.314\n",
      "Time:                        14:15:18   Log-Likelihood:                -5503.0\n",
      "No. Observations:                 270   AIC:                         1.101e+04\n",
      "Df Residuals:                     268   BIC:                         1.102e+04\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "================================================================================\n",
      "                   coef    std err          t      P>|t|      [0.025      0.975]\n",
      "--------------------------------------------------------------------------------\n",
      "Intercept      7.29e+07   1.49e+07      4.908      0.000    4.37e+07    1.02e+08\n",
      "is_first_day   2.12e+07    2.1e+07      1.009      0.314   -2.02e+07    6.26e+07\n",
      "==============================================================================\n",
      "Omnibus:                      411.838   Durbin-Watson:                   2.115\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            76209.844\n",
      "Skew:                           7.492   Prob(JB):                         0.00\n",
      "Kurtosis:                      83.930   Cond. No.                         2.62\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_time_stamps['is_first_day'] = (df_time_stamps['Day'] == 1).astype(int)\n",
    "\n",
    "matching_vars = ['Year', 'Runtime', 'budget', 'Month'] \n",
    "\n",
    "\n",
    "df_matched_treatement, df_matched_control = analyse(df_time_stamps, 'is_first_day', matching_vars, \n",
    "                                                    'Box_office', 'Wikipedia ID', onehot_vars)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0c963a09",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.668118\n",
      "         Iterations 6\n",
      "1764 1917\n",
      "Time : 2.5435779094696045\n",
      "Test for Box_office ~ is_friday\n",
      "\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:             Box_office   R-squared:                       0.015\n",
      "Model:                            OLS   Adj. R-squared:                  0.014\n",
      "Method:                 Least Squares   F-statistic:                     12.30\n",
      "Date:                Thu, 30 Nov 2023   Prob (F-statistic):           0.000478\n",
      "Time:                        14:16:07   Log-Likelihood:                -15987.\n",
      "No. Observations:                 802   AIC:                         3.198e+04\n",
      "Df Residuals:                     800   BIC:                         3.199e+04\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept    9.52e+07    5.5e+06     17.324      0.000    8.44e+07    1.06e+08\n",
      "is_friday  -2.726e+07   7.77e+06     -3.507      0.000   -4.25e+07    -1.2e+07\n",
      "==============================================================================\n",
      "Omnibus:                      483.673   Durbin-Watson:                   1.945\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             4718.034\n",
      "Skew:                           2.621   Prob(JB):                         0.00\n",
      "Kurtosis:                      13.663   Cond. No.                         2.62\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_time_stamps['is_friday'] = (df_time_stamps['Weekday Name'] == 'Friday').astype(int)\n",
    "\n",
    "matching_vars = ['Year', 'Runtime', 'budget', 'Day'] \n",
    "\n",
    "df_matched_treatement, df_matched_control = analyse(df_time_stamps, 'is_friday', matching_vars, \n",
    "                                                    'Box_office', 'Wikipedia ID', onehot_vars)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "3ca67bff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.588746\n",
      "         Iterations 6\n",
      "1602 3895\n",
      "Time : 4.807483196258545\n",
      "Test for won_oscar ~ is_month\n",
      "\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:              won_oscar   R-squared:                       0.005\n",
      "Model:                            OLS   Adj. R-squared:                  0.005\n",
      "Method:                 Least Squares   F-statistic:                     12.81\n",
      "Date:                Thu, 30 Nov 2023   Prob (F-statistic):           0.000352\n",
      "Time:                        14:21:27   Log-Likelihood:                -138.08\n",
      "No. Observations:                2406   AIC:                             280.2\n",
      "Df Residuals:                    2404   BIC:                             291.7\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept      0.0898      0.007     12.146      0.000       0.075       0.104\n",
      "is_month      -0.0374      0.010     -3.578      0.000      -0.058      -0.017\n",
      "==============================================================================\n",
      "Omnibus:                     1607.524   Durbin-Watson:                   2.006\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            12606.024\n",
      "Skew:                           3.312   Prob(JB):                         0.00\n",
      "Kurtosis:                      12.048   Cond. No.                         2.62\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_time_stamps['won_oscar'] = (df_time_stamps['num_oscars_won'] > 0).astype(int)\n",
    "df_time_stamps['is_month'] = (df_time_stamps['Month'] <= 4).astype(int)\n",
    "\n",
    "\n",
    "matching_vars = ['Year', 'Runtime', 'budget', 'Day', 'Weekday'] \n",
    "\n",
    "\n",
    "\n",
    "df_matched_treatement, df_matched_control = analyse(df_time_stamps, 'is_month', matching_vars, \n",
    "                                                    'won_oscar', 'Wikipedia ID', onehot_vars)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "bd8f70ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.622821\n",
      "         Iterations 6\n",
      "579 1155\n",
      "Time : 0.5276849269866943\n",
      "Test for budget ~ is_month\n",
      "\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                 budget   R-squared:                       0.012\n",
      "Model:                            OLS   Adj. R-squared:                  0.010\n",
      "Method:                 Least Squares   F-statistic:                     6.280\n",
      "Date:                Thu, 30 Nov 2023   Prob (F-statistic):             0.0125\n",
      "Time:                        14:25:18   Log-Likelihood:                -9543.6\n",
      "No. Observations:                 504   AIC:                         1.909e+04\n",
      "Df Residuals:                     502   BIC:                         1.910e+04\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept   3.407e+07   2.56e+06     13.328      0.000     2.9e+07    3.91e+07\n",
      "is_month   -9.059e+06   3.61e+06     -2.506      0.013   -1.62e+07   -1.96e+06\n",
      "==============================================================================\n",
      "Omnibus:                      281.266   Durbin-Watson:                   2.068\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             1613.789\n",
      "Skew:                           2.507   Prob(JB):                         0.00\n",
      "Kurtosis:                      10.190   Cond. No.                         2.62\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_time_stamps['is_month'] = (df_time_stamps['Month'] <= 4).astype(int)\n",
    "\n",
    "\n",
    "matching_vars = ['Year', 'Runtime'] \n",
    "\n",
    "\n",
    "df_matched_treatement, df_matched_control = analyse(df_time_stamps[df_time_stamps['Year']>2005], 'is_month', matching_vars, \n",
    "                                                    'budget', 'Wikipedia ID', onehot_vars)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8136189",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
